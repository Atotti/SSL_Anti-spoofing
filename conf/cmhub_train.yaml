# CM Hub training configuration (independent of Fairseq)

data:
  train_scp: null
  dev_scp: null
  labels: null

train:
  out_dir: ./outputs
  max_epochs: 30
  batch_size: 32
  lr: 0.000001
  seed: 1234

wandb:
  enable: true
  run_name: null

hydra:
  run:
    dir: ${train.out_dir}
  job:
    name: cmhub_train
  sweep:
    dir: ./multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}